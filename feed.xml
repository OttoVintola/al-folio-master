<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://ottovintola.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ottovintola.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-03-11T11:07:17+00:00</updated><id>https://ottovintola.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Advanced SQL and Query Optimization</title><link href="https://ottovintola.github.io/blog/2024/Advanced-SQL/" rel="alternate" type="text/html" title="Advanced SQL and Query Optimization"/><published>2024-02-26T11:12:00+00:00</published><updated>2024-02-26T11:12:00+00:00</updated><id>https://ottovintola.github.io/blog/2024/Advanced%20SQL</id><content type="html" xml:base="https://ottovintola.github.io/blog/2024/Advanced-SQL/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>Recently, I’ve been studying SQL for some data engineering tasks. I came across a course that mentioned about using Arrays – which I did not even know existed in SQL, additionally, there were ideas and best practices about how to make queries more efficient. I knew that most database systems have <strong>query optimizers</strong> that attempt to interpret/execute the query efficiently, but there were some strategies that could still make a massive impact on the performance of the query.</p> <p><br/></p> <h2 id="nested-data">Nested Data</h2> <p>Lets imagine a hypothetical dataset that has the information about people and their jobs. The data is stored in two tables called <code class="language-plaintext highlighter-rouge">Employees</code> and the columns are <code class="language-plaintext highlighter-rouge">ID</code>, <code class="language-plaintext highlighter-rouge">Name</code>, <code class="language-plaintext highlighter-rouge">Age</code>, and then there is another table called <code class="language-plaintext highlighter-rouge">Information</code> with columns <code class="language-plaintext highlighter-rouge">JobID</code>, <code class="language-plaintext highlighter-rouge">Job</code> and <code class="language-plaintext highlighter-rouge">Tasks</code>. The <code class="language-plaintext highlighter-rouge">JobID</code> is a foreign key that references the <code class="language-plaintext highlighter-rouge">ID</code> in the <code class="language-plaintext highlighter-rouge">people</code> table.</p> <p><strong>Employees Table</strong></p> <table> <thead> <tr> <th style="text-align: left">ID</th> <th style="text-align: left">Name</th> <th style="text-align: left">Age</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">101</td> <td style="text-align: left">John</td> <td style="text-align: left">45</td> </tr> <tr> <td style="text-align: left">42</td> <td style="text-align: left">Jack</td> <td style="text-align: left">35</td> </tr> <tr> <td style="text-align: left">89</td> <td style="text-align: left">Jill</td> <td style="text-align: left">58</td> </tr> </tbody> </table> <p><br/></p> <p><strong>Information Table</strong></p> <table> <thead> <tr> <th style="text-align: left">JobID</th> <th style="text-align: left">Job</th> <th style="text-align: left">Tasks</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">89</td> <td style="text-align: left">Software</td> <td style="text-align: left">Coding</td> </tr> <tr> <td style="text-align: left">42</td> <td style="text-align: left">Sales</td> <td style="text-align: left">Negotiating</td> </tr> <tr> <td style="text-align: left">101</td> <td style="text-align: left">Legal</td> <td style="text-align: left">Advise</td> </tr> </tbody> </table> <p><br/></p> <p>We can either construct the tables like this, or we can use a nested column (a row inside of a row) to store the information. You can think of the row entry being used as a reference to more rows. The nested data structure would look like this:</p> <p><strong>Employees_Information</strong></p> <table> <thead> <tr> <th style="text-align: left">ID</th> <th style="text-align: left">Name</th> <th style="text-align: left">Age</th> <th style="text-align: left">Jobs</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">101</td> <td style="text-align: left">John</td> <td style="text-align: left">45</td> <td style="text-align: left">{Job: Legal, Tasks: Advise}</td> </tr> <tr> <td style="text-align: left">42</td> <td style="text-align: left">Jack</td> <td style="text-align: left">35</td> <td style="text-align: left">{Job: Sales, Tasks: Negotiating}</td> </tr> <tr> <td style="text-align: left">89</td> <td style="text-align: left">Jill</td> <td style="text-align: left">58</td> <td style="text-align: left">{Job: Software, Tasks: Coding}</td> </tr> </tbody> </table> <p><br/> The nested data structure is more efficient because it reduces the number of joins that need to be performed. Additionally, it reduces the database schema complexity making it easier to understand and maintain.</p> <p>To extract the data from this nested structure, we can use a query like this:</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="n">ID</span><span class="p">,</span> <span class="n">Name</span><span class="p">,</span> <span class="n">Age</span>
<span class="k">FROM</span> <span class="n">Employees_Information</span><span class="p">,</span>
    <span class="n">Jobs</span><span class="p">.</span><span class="n">Job</span> <span class="k">AS</span> <span class="n">Job</span><span class="p">,</span> <span class="n">Jobs</span><span class="p">.</span><span class="n">Tasks</span> <span class="k">AS</span> <span class="n">Task</span>
</code></pre></div></div> <p>Which would result in a table like this:</p> <table> <thead> <tr> <th style="text-align: left">ID</th> <th style="text-align: left">Name</th> <th style="text-align: left">Age</th> <th style="text-align: left">Job</th> <th style="text-align: left">Task</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">101</td> <td style="text-align: left">John</td> <td style="text-align: left">45</td> <td style="text-align: left">Legal</td> <td style="text-align: left">Advise</td> </tr> <tr> <td style="text-align: left">42</td> <td style="text-align: left">Jack</td> <td style="text-align: left">35</td> <td style="text-align: left">Sales</td> <td style="text-align: left">Negotiating</td> </tr> <tr> <td style="text-align: left">89</td> <td style="text-align: left">Jill</td> <td style="text-align: left">58</td> <td style="text-align: left">Software</td> <td style="text-align: left">Coding</td> </tr> </tbody> </table> <p><br/></p> <h2 id="repeated-data">Repeated Data</h2> <p>Another a more realistic scenario is when we can have multiple tasks per job. In this scenario we can use an <code class="language-plaintext highlighter-rouge">Array</code> to store the tasks. The <code class="language-plaintext highlighter-rouge">Employees</code> table would look like this:</p> <p><strong>Employees_Information</strong></p> <table> <thead> <tr> <th style="text-align: left">ID</th> <th style="text-align: left">Name</th> <th style="text-align: left">Age</th> <th style="text-align: left">Job</th> <th style="text-align: left">Tasks</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">101</td> <td style="text-align: left">John</td> <td style="text-align: left">45</td> <td style="text-align: left">Legal</td> <td style="text-align: left">[Advise, Research]</td> </tr> <tr> <td style="text-align: left">42</td> <td style="text-align: left">Jack</td> <td style="text-align: left">35</td> <td style="text-align: left">Sales</td> <td style="text-align: left">[Negotiating, Marketing]</td> </tr> <tr> <td style="text-align: left">89</td> <td style="text-align: left">Jill</td> <td style="text-align: left">58</td> <td style="text-align: left">Software</td> <td style="text-align: left">[Coding, Testing]</td> </tr> </tbody> </table> <p><br/> To extract the data from this array structure, we can use a query like this:</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="n">ID</span><span class="p">,</span> <span class="n">Name</span><span class="p">,</span> <span class="n">Age</span><span class="p">,</span> <span class="n">Job</span><span class="p">,</span> <span class="n">Task</span>
<span class="k">FROM</span> <span class="n">Employees_Information</span><span class="p">,</span>
    <span class="k">UNNEST</span><span class="p">(</span><span class="n">Tasks</span><span class="p">)</span> <span class="k">AS</span> <span class="n">Task</span>
</code></pre></div></div> <p>From this query we would get a table like this:</p> <table> <thead> <tr> <th style="text-align: left">ID</th> <th style="text-align: left">Name</th> <th style="text-align: left">Age</th> <th style="text-align: left">Job</th> <th style="text-align: left">Task</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">101</td> <td style="text-align: left">John</td> <td style="text-align: left">45</td> <td style="text-align: left">Legal</td> <td style="text-align: left">Advise</td> </tr> <tr> <td style="text-align: left">101</td> <td style="text-align: left">John</td> <td style="text-align: left">45</td> <td style="text-align: left">Legal</td> <td style="text-align: left">Research</td> </tr> <tr> <td style="text-align: left">42</td> <td style="text-align: left">Jack</td> <td style="text-align: left">35</td> <td style="text-align: left">Sales</td> <td style="text-align: left">Negotiating</td> </tr> <tr> <td style="text-align: left">42</td> <td style="text-align: left">Jack</td> <td style="text-align: left">35</td> <td style="text-align: left">Sales</td> <td style="text-align: left">Marketing</td> </tr> <tr> <td style="text-align: left">89</td> <td style="text-align: left">Jill</td> <td style="text-align: left">58</td> <td style="text-align: left">Software</td> <td style="text-align: left">Coding</td> </tr> <tr> <td style="text-align: left">89</td> <td style="text-align: left">Jill</td> <td style="text-align: left">58</td> <td style="text-align: left">Software</td> <td style="text-align: left">Testing</td> </tr> </tbody> </table> <p><br/> Note the difference thus between using a nested structure and arrays!</p> <p>It is also possible to have nested structures within arrays, and arrays within nested structures. This can be useful for storing complex data structures in a single column.</p> <p><br/></p> <h2 id="query-optimization">Query Optimization</h2> <p>The three main strategies for optimizing queries that I recently learned are</p> <ol> <li>Only select columns needed/wanted</li> <li>Read less data</li> <li>Avoid N:N Joins</li> </ol> <p><br/></p> <h4 id="1-only-select-columns-neededwanted">1. Only select columns needed/wanted</h4> <p>Usually it is tempting to just get everything with <code class="language-plaintext highlighter-rouge">SELECT * FROM ...</code> but this is not efficient if all of the columns are not required for the query/results. To highlight the difference consider these two following queries ran on the <a href="https://cloud.google.com/bigquery/public-data"><code class="language-plaintext highlighter-rouge">bigquery-public-data.github_repos.contents</code></a> table:</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="nv">`bigquery-public-data.github_repos.contents
</span></code></pre></div></div> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="k">size</span><span class="p">,</span> <span class="nb">binary</span> <span class="k">FROM</span> <span class="nv">`bigquery-public-data.github_repos.contents
</span></code></pre></div></div> <p>Data processed: 2682.118 GB <br/> Data processed: 2.531 GB</p> <p><br/></p> <h4 id="2-read-less-data">2. Read less data</h4> <p>This point seems obvious, however, it might not be as straightforward as it seems. The idea is to be parsimonius about what columns to include in the query. Avoid as hard as you can to include columns that are not needed. Well, how can you do that? If there is a column with a 1-to-1 relationship with another column, then you can exclude one of them and use the other. For example, if you have a column <code class="language-plaintext highlighter-rouge">Country</code> and another column <code class="language-plaintext highlighter-rouge">CountryCode</code> you can exclude one of them and this will effectively reduce the amount of data read.</p> <p>Consider the query below:</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="n">Country</span><span class="p">,</span> <span class="n">Population</span><span class="p">,</span> <span class="n">GDP</span><span class="p">,</span> <span class="n">CountryCode</span>
<span class="k">FROM</span> <span class="n">CountryTable</span>
<span class="k">WHERE</span> <span class="n">CountryCode</span> <span class="o">=</span> <span class="s1">'US'</span>
</code></pre></div></div> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="n">Country</span><span class="p">,</span> <span class="n">Population</span><span class="p">,</span> <span class="n">GDP</span>
<span class="k">FROM</span> <span class="n">CountryTable</span>
<span class="k">WHERE</span> <span class="n">Country</span> <span class="o">=</span> <span class="s1">'United States'</span>
</code></pre></div></div> <p>Since, the <code class="language-plaintext highlighter-rouge">CountryCode</code> and <code class="language-plaintext highlighter-rouge">Country</code> have a 1-to-1 correspondence, we can exclude one of them and use the other.</p> <p><br/></p> <h4 id="3-avoid-nn-joins">3. Avoid N:N Joins</h4> <p>The idea here is to avoid joining tables that have a many-to-many relationship and instead separate the queries if possible, and then use an <code class="language-plaintext highlighter-rouge">INNER JOIN</code> to combine the results.</p> <p>The query ran on the <code class="language-plaintext highlighter-rouge">bigquery-public-data.github_repos</code> below shows the difference</p> <p>Slow</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                 <span class="k">SELECT</span> <span class="n">repo</span><span class="p">,</span>
                     <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">c</span><span class="p">.</span><span class="n">committer</span><span class="p">.</span><span class="n">name</span><span class="p">)</span> <span class="k">as</span> <span class="n">num_committers</span><span class="p">,</span>
                     <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">f</span><span class="p">.</span><span class="n">id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">num_files</span>
                 <span class="k">FROM</span> <span class="nv">`bigquery-public-data.github_repos.commits`</span> <span class="k">AS</span> <span class="k">c</span><span class="p">,</span>
                     <span class="k">UNNEST</span><span class="p">(</span><span class="k">c</span><span class="p">.</span><span class="n">repo_name</span><span class="p">)</span> <span class="k">AS</span> <span class="n">repo</span>
                 <span class="k">INNER</span> <span class="k">JOIN</span> <span class="nv">`bigquery-public-data.github_repos.files`</span> <span class="k">AS</span> <span class="n">f</span>
                     <span class="k">ON</span> <span class="n">f</span><span class="p">.</span><span class="n">repo_name</span> <span class="o">=</span> <span class="n">repo</span>
                 <span class="k">WHERE</span> <span class="n">f</span><span class="p">.</span><span class="n">repo_name</span> <span class="k">IN</span> <span class="p">(</span> <span class="s1">'tensorflow/tensorflow'</span><span class="p">,</span> <span class="s1">'facebook/react'</span><span class="p">,</span> <span class="s1">'twbs/bootstrap'</span><span class="p">,</span> <span class="s1">'apple/swift'</span><span class="p">,</span> <span class="s1">'Microsoft/vscode'</span><span class="p">,</span> <span class="s1">'torvalds/linux'</span><span class="p">)</span>
                 <span class="k">GROUP</span> <span class="k">BY</span> <span class="n">repo</span>
                 <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">repo</span>             
</code></pre></div></div> <p>Fast</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>             <span class="k">WITH</span> <span class="n">commits</span> <span class="k">AS</span>
                   <span class="p">(</span>
                   <span class="k">SELECT</span> <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">committer</span><span class="p">.</span><span class="n">name</span><span class="p">)</span> <span class="k">AS</span> <span class="n">num_committers</span><span class="p">,</span> <span class="n">repo</span>
                   <span class="k">FROM</span> <span class="nv">`bigquery-public-data.github_repos.commits`</span><span class="p">,</span>
                       <span class="k">UNNEST</span><span class="p">(</span><span class="n">repo_name</span><span class="p">)</span> <span class="k">as</span> <span class="n">repo</span>
                   <span class="k">WHERE</span> <span class="n">repo</span> <span class="k">IN</span> <span class="p">(</span> <span class="s1">'tensorflow/tensorflow'</span><span class="p">,</span> <span class="s1">'facebook/react'</span><span class="p">,</span> <span class="s1">'twbs/bootstrap'</span><span class="p">,</span> <span class="s1">'apple/swift'</span><span class="p">,</span> <span class="s1">'Microsoft/vscode'</span><span class="p">,</span> <span class="s1">'torvalds/linux'</span><span class="p">)</span>
                   <span class="k">GROUP</span> <span class="k">BY</span> <span class="n">repo</span>
                   <span class="p">),</span>
                   <span class="n">files</span> <span class="k">AS</span> 
                   <span class="p">(</span>
                   <span class="k">SELECT</span> <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">num_files</span><span class="p">,</span> <span class="n">repo_name</span> <span class="k">as</span> <span class="n">repo</span>
                   <span class="k">FROM</span> <span class="nv">`bigquery-public-data.github_repos.files`</span>
                   <span class="k">WHERE</span> <span class="n">repo_name</span> <span class="k">IN</span> <span class="p">(</span> <span class="s1">'tensorflow/tensorflow'</span><span class="p">,</span> <span class="s1">'facebook/react'</span><span class="p">,</span> <span class="s1">'twbs/bootstrap'</span><span class="p">,</span> <span class="s1">'apple/swift'</span><span class="p">,</span> <span class="s1">'Microsoft/vscode'</span><span class="p">,</span> <span class="s1">'torvalds/linux'</span><span class="p">)</span>
                   <span class="k">GROUP</span> <span class="k">BY</span> <span class="n">repo</span>
                   <span class="p">)</span>
                   <span class="k">SELECT</span> <span class="n">commits</span><span class="p">.</span><span class="n">repo</span><span class="p">,</span> <span class="n">commits</span><span class="p">.</span><span class="n">num_committers</span><span class="p">,</span> <span class="n">files</span><span class="p">.</span><span class="n">num_files</span>
                   <span class="k">FROM</span> <span class="n">commits</span> 
                   <span class="k">INNER</span> <span class="k">JOIN</span> <span class="n">files</span>
                       <span class="k">ON</span> <span class="n">commits</span><span class="p">.</span><span class="n">repo</span> <span class="o">=</span> <span class="n">files</span><span class="p">.</span><span class="n">repo</span>
                   <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">repo</span>      
                   
</code></pre></div></div> <p>The time difference is not significant for this particular query, but if we run it again and again, the difference will add up.</p> <p>Time to run: 13.028 seconds <br/> Time to run: 4.413 seconds <br/><br/></p> <h2 id="conclusion">Conclusion</h2> <p>When I was first learning about SQL, it was in PostgreSQL, which famously does not have arrays built in, so I was quite surprised that they actually exist. Additionally, the idea of nesting data seems logical in order to keep the database schemas more simple – having to do a myriad of <code class="language-plaintext highlighter-rouge">JOIN</code> statements can make queries complex. Lastly, it is also important to track the performance of queries, especially if they are ran on a frequent bases, and attempt to optimize with these principles or just common sense. <br/> <br/> <br/> <br/></p> <h2 id="references">References</h2> <ol> <li><a href="https://www.kaggle.com/learn/advanced-sql">Advanced SQL</a> by Alexis Cook on Kaggle</li> </ol>]]></content><author><name></name></author><category term="Databases"/><category term="SQL"/><category term="Sustainability"/><summary type="html"><![CDATA[What I learned about SQL and making queries run faster and more sustainably than before]]></summary></entry><entry><title type="html">Multilayer Perceptrons and Backpropagation</title><link href="https://ottovintola.github.io/blog/2024/Multilayer-Perceptrons/" rel="alternate" type="text/html" title="Multilayer Perceptrons and Backpropagation"/><published>2024-02-20T00:00:00+00:00</published><updated>2024-02-20T00:00:00+00:00</updated><id>https://ottovintola.github.io/blog/2024/Multilayer%20Perceptrons</id><content type="html" xml:base="https://ottovintola.github.io/blog/2024/Multilayer-Perceptrons/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>This article will cover the basics about multilayer perceptrons – and the relevant equations to illustrate the inner workings – and how they are trained on data. The goal of this article is not to be a rigorous research paper or a comprehensive guide to the topic, but rather to provide a brief overview of the topic while giving myself the opportunity to recap the important concepts.</p> <p>This will serve as the first addition to the deep learning series, which means there is a small detour to take about deep learning. The basic idea of deep learning will be covered and then we will move on to the main topic of the article. At the end there will be references.</p> <hr/> <h2 id="what-is-deep-learning">What is deep learning?</h2> <p>In a traditional machine learning problem feature engineering would be required. Predicting from the data with human made features, basically the engineer is telling the computer what parts of the data it should use to complete the task. However, sometimes features are hard to specify – especially when dealing with problems that can have many possible options for features such as <strong>image classification</strong> or <strong>natural language processing</strong>.</p> <p>This is where deep learning comes in. <code class="language-plaintext highlighter-rouge">Deep learning is a subset of machine learning where the labels are defined – or learned as we will later see – by the computer itself.</code> <strong>Deep learning</strong> itself is a subset of <strong>representation learning</strong> <d-cite key="bengio2014representation"></d-cite> where we use machine learning to find the mapping from the input to the output and also discover the mapping itself. This means that there is no direct feature engineering required from the engineers, however, providing clean and purposeful data is still crucial – its not possible to just throw in information and expect the wanted results.</p> <p>Sometimes feature engineering is important, like when we want a specified result from a well structured data set, however, deep learning is a powerful tool when dealing with unstructured data. Lets imagine that someone asked you to define the features of an image classification task, what would you say? Maybe its some prominent shape or color. While these may seem natural to a human, they are hard to define to a computer.</p> <p>Deep learning has been around for a long time now – the first neural network was created in 1958 <d-cite key="Rosenblatt1958ThePA"></d-cite> – but it has only recently become popular due to the increase in computational power and the increase in the amount of data available.</p> <hr/> <h2 id="linear-classifier">Linear Classifier</h2> <p>Before we defining multilayer perceptrons we need to understand the linear classifier. Lets say that we had a binary classification problem: our data is \((x^1, y^1) ... (x^n, y^n)\) where \(x^i\) is the input and \(y^i\) is the output where \(x \in R\) and \(y \in \{0, 1\}\). Then with the data the aim is to find a function:</p> \[f(x) = \sigma\left( \sum_{i=1}^{n} w_i x_i + b \right) = \sigma\left(\mathbf{w}^T\mathbf{x} + \mathbf{b}\right)\] <p>where \(\sigma\) is the sigmoid function and \(w_i\) and \(b\) are the weights and bias of the function. The sigmoid function is defined as \(\sigma(x) = \frac{1}{1 + e^{-x}}\).</p> <p>Now with the logistic regression model the output is between 0 and 1, and can be interpreted as the probability that \(x\) belongs to one of the classes \(p(y = 1 \mid x) = f(x)\)</p> <p>At this point, training the classifier would mean finding some \(\textbf{w}\) and \(\textbf{b}\) that would classify most of our examples as correct. This means finding the likelihood function</p> \[p(data | \textbf{w}, \textbf{b}) = \prod_{i=1}^{n} p(y^i | x^i, \textbf{w}, \textbf{b})\] <p>that would maximize the probability of the data given the parameters. This is done by maximizing the log likelihood function (or more commonly minimze the negative of it)</p> \[L(\textbf{w}, \textbf{b}) = - \sum_{i=1}^{n} y^i \log(f(x^i)) + (1 - y^i) \log(1 - f(x^i))\] <p>This loss function specifically is called the cross-entropy loss function and the training of the model is done by minimizing it.</p> <hr/> <h2 id="gradient-descent">Gradient Descent</h2> <p>For now a quick explanation of the minimization process – this will serve as the lead to backpropagation. Most of the training (finding optimal parameters) is done by using the gradient descent algorithm. Which a is a first order optimization algorithm that is used to find the minimum of a function. The algorithm works by taking the derivative of the function at a point and then moving in the opposite direction of the derivative. This is done iteratively until the algorithm converges to a minimum.</p> <p>An image highlights the process quite nicely. The arrows represent the direction of the gradient and the red dot is the minimum of the function. The representation is a contour plot where the lines are orthogonal to the largest gradient. In reality the function is multidimensional and the gradient is a vector, but the idea is the same.</p> <figure style="text-align: center;"> <img src="/assets/img/MLP/GD.png" alt="Gradient Descent" style="width: 50%; height: auto; display: block; margin: 0 auto;"/> <figcaption style="font-style: italic;">Gradient Descent from Wikipedia</figcaption> </figure> <p>The equation representing the iterative process of updating model parameters is</p> \[\theta_{t+1} = \theta_t - \alpha g(\theta_t)\] <p>where \(\theta\) is the parameter, \(\alpha\) is the learning rate and \(g(\theta)\) is the gradient of the function at the point \(\theta\). Now, with backpropagation we can <strong>efficiently</strong> calculate the gradient of the loss function with respect to the parameters of the model and then use gradient descent to update the parameters.</p> <hr/> <h2 id="multilayer-perceptrons">Multilayer Perceptrons</h2> <p>Now, with this information we can define what is a multilayer perceptron (MLP) <d-cite key="Rosenblatt1958ThePA"></d-cite>. They are basically regarded as the general case for a neural network where each neuron implements a function</p> \[f(x) = \phi\left( \sum_{i=1}^{n} w_i x_i + b \right) = \phi\left(\mathbf{w}^T\mathbf{x} + \mathbf{b}\right)\] <p>Where \(\phi\) implements a nonlinear activation function.</p> <p>The idea of the multilayer perceptron is to stack multiple layers of neurons on top of each other. The first layer is the input layer, the last layer is the output layer and the layers in between are called hidden layers. The hidden layers are the ones that make the network deep.</p> <figure style="text-align: center;"> <img src="/assets/img/MLP/MLP.jpg" alt="Fully Connected MLP" style="width: 50%; height: auto; display: block; margin: 0 auto;"/> <figcaption style="font-style: italic;">MLP</figcaption> </figure> <p>Typically, mathematically we represent the network in a more compact style where each node compresses an entire layer.</p> \[h_1 = \phi\left(\mathbf{W}_1^T\mathbf{x} + \mathbf{b}_1\right) \rightarrow h_2 = \phi\left(\mathbf{W}_2^T\mathbf{h}_1 + \mathbf{b}_2\right) \rightarrow y = \phi\left(\mathbf{W}_3^T\mathbf{h}_2 + \mathbf{b}_3\right)\] <p>We can think of the neural network as receiving the input \(x\) and then applying a function \(f(x, \theta)\) where \(\theta\) are the parameters of the model. Our neural network would be \(f_3(f_2(f_1(x, \theta_1), \theta_2), \theta_3)\) where \(f_1, f_2, f_3\) are the functions of the layers and \(\theta_1, \theta_2, \theta_3\) are the parameters of the layers.</p> <p>Now, if the multilayer perceptron is solving a classification problem, the loss function</p> \[L(\theta) = - \sum_{i=1}^{n} y^i \log(f(x^i, \theta)) + (1 - y^i) \log(1 - f(x^i, \theta))\] <p>is used to train the model – note \(\theta\) contains the model parameters \((\textbf{W}, \textbf{b})\). The training is done by using the gradient descent algorithm to minimize the loss function.</p> <hr/> <h2 id="backpropagation">Backpropagation</h2> <p>With massive neural networks calculating gradients becomes computationally expensive and slow. This is where backpropagation comes in. It is a method used to calculate the gradient of the loss function with respect to the parameters and the predicted label. The method is based on the chain rule of calculus and is used to calculate the gradient of the loss function with respect to the parameters of the model.</p> <p>We apply the chain rule to the loss function with respect to each of the parameters</p> \[\frac{\partial L}{\partial \theta} = \sum\frac{\partial L}{\partial y} \frac{\partial y}{\partial \theta}\] \[\frac{\partial L}{\partial h} = \sum\frac{\partial L}{\partial y} \frac{\partial y}{\partial h}\] \[\frac{\partial L}{\partial w} = \sum\frac{\partial L}{\partial h} \frac{\partial h}{\partial w}\] <p>where \(\theta\) are the parameters of the model and \(f\) is the output of the model. The first term is the gradient of the loss function with respect to the output of the model and the second term is the gradient of the output of the model with respect to the parameters of the model. The partial derivatives have to be summed to calculate the effect of the entire layer.</p> <p><code class="language-plaintext highlighter-rouge">From here we can notice that backpropagation relies on the idea that, each connection in the network is affected by the previous layers value propagating to the output layer where the loss was calculated.</code> Recursively calculating derivatives of the loss function with respect to the parameters of the model and the output of the model is the main idea of backpropagation. <strong>Storing the intermediate steps of the calculation is crucial for the efficiency</strong>.</p> <hr/> <h2 id="conclusion">Conclusion</h2> <p>Deep learning has been around for a long time, but it has only recently become popular due to the increase in computational power and the increase in the amount of data available. Deep learning is a subset of machine learning where the labels are defined by the computer itself.</p> <p>In this article we covered the basics about multilayer perceptrons – and the relevant equations – to hopefully shed some light into this bundle of complexity. I got to recap many important topics and ideas as well.</p> <p>I want to take the time to finally thank you (the reader) for reading this article. I hope you found it interesting and that you learned something new. If you have any questions or comments, feel free to email me at <code class="language-plaintext highlighter-rouge">otto.vintola@aalto.fi</code>.</p>]]></content><author><name>Otto Vintola</name></author><category term="MachineLearning"/><category term="DeepLearning"/><category term="NeuralNetworks"/><category term="Backpropagation"/><summary type="html"><![CDATA[A brief introduction to the theory behind deep learning, linear classifiers, gradient descent and backpropagation explained by going through the necessary information to understand multilayer perceptrons.]]></summary></entry></feed>